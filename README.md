# HITL Multi-Agent Code Refactoring System

**Kaggle Agents Intensive Capstone Project - Freestyle Track**

A human-in-the-loop (HITL) multi-agent system that incrementally refactors the [arc-dsl codebase](https://github.com/michaelhodel/arc-dsl) through intelligent analysis, proposal generation, automated testing, and documentation. Features a **two-stage HITL workflow**: review proposals before testing, then commit or rollback based on test results. This "meta-agent" approachâ€”agents that help refactor and improve codeâ€”demonstrates an innovative application of AI agents for software engineering.

## ğŸ¯ Project Overview

### The Problem

The ARC-DSL (Abstraction and Reasoning Corpus Domain Specific Language) codebase suffers from:
- **Type Ambiguity**: Overuse of Union types and isinstance checks making code hard to reason about
- **Poor Organization**: 200+ functions in `dsl.py` with identical signatures but no grouping mechanism
- **Complexity**: Manual refactoring is risky due to tight coupling and limited test coverage

### The Solution

A multi-agent system with two-stage human oversight that:
1. **Analyzes** code for refactoring opportunities using MCP professional tools (Rope, Radon, Vulture, Pyrefly)
2. **Proposes** incremental, backward-compatible changes in structured JSON format
3. **Reviews** at Checkpoint #1: Human approves/rejects proposal before any changes
4. **Tests** automatically via pytest if approved, with backup creation
5. **Reviews** at Checkpoint #2: Human commits or rolls back based on test results
6. **Documents** all changes with migration guides (if committed)
7. **Learns** from human approval patterns via Memory Bank

### Why Agents?

Traditional refactoring tools are rule-based and brittle. Our agent-based approach provides:
- **Intelligence**: LLMs understand code semantics, not just syntax
- **Adaptability**: Learns from human decisions to improve future proposals
- **Safety**: HITL checkpoints prevent automated mistakes
- **Coordination**: Multiple specialized agents collaborate on complex tasks

## ğŸ—ï¸ Architecture

### System Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     COORDINATOR AGENT                       â”‚
â”‚  Orchestrates workflow: Analysis â†’ Refactor â†’ Validate      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â–¼               â–¼               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ANALYSIS    â”‚  â”‚  REFACTOR    â”‚  â”‚ VALIDATION   â”‚
    â”‚   AGENT      â”‚  â”‚   AGENT      â”‚  â”‚   AGENT      â”‚
    â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
    â”‚ â€¢ Find type  â”‚  â”‚ â€¢ Generate   â”‚  â”‚ â€¢ Check      â”‚
    â”‚   issues     â”‚  â”‚   proposals  â”‚  â”‚   backwards  â”‚
    â”‚ â€¢ Group      â”‚  â”‚ â€¢ Ensure     â”‚  â”‚   compat     â”‚
    â”‚   functions  â”‚  â”‚   compat     â”‚  â”‚ â€¢ Assess riskâ”‚
    â”‚ â€¢ MCP tools  â”‚  â”‚ â€¢ JSON fmt   â”‚  â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚               â”‚               â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ CHECKPOINT #1   â”‚
                   â”‚ Review Proposal â”‚
                   â”‚                 â”‚
                   â”‚ Approve/Reject/ â”‚
                   â”‚ Skip/Abort      â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ (if approved)
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Apply Changes  â”‚
                   â”‚  Create Backup  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Run pytest on  â”‚
                   â”‚ arc-dsl/tests.pyâ”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ CHECKPOINT #2   â”‚
                   â”‚ Review Tests    â”‚
                   â”‚                 â”‚
                   â”‚ Commit/Rollback/â”‚
                   â”‚ Abort           â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ (if committed)
                            â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ DOCUMENTATION    â”‚
                  â”‚     AGENT        â”‚
                  â”‚                  â”‚
                  â”‚ â€¢ Docstrings     â”‚
                  â”‚ â€¢ Changelog      â”‚
                  â”‚ â€¢ Migration docs â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Roles

| Agent | Purpose | Key Responsibilities |
|-------|---------|---------------------|
| **Coordinator** | Workflow orchestration | Manages multi-agent pipeline, handles retries |
| **Analysis** | Code inspection | Identifies type ambiguities, finds groupable functions |
| **Refactor** | Code transformation | Generates backward-compatible refactoring proposals |
| **Validation** | Quality assurance | Runs tests, checks compatibility, assesses risk |
| **Documentation** | Knowledge capture | Creates docstrings, changelogs, migration guides |

### Custom Tools

```python
class RefactoringTools:
    # Basic file operations
    read_file(file_path)           # Load source code
    write_file(file_path, content) # Save refactored code (with timestamped backup)
    
    # MCP-enhanced analysis (uses mcp-python-refactoring package)
    analyze_type_usage(file_path)  # Find isinstance checks & Union types
                                   # Falls back to MCP: Rope, Radon, Vulture, Pyrefly
    
    # Code structure analysis
    find_function_signatures(...)  # Identify functions with identical signatures
    
    # Testing (used by two-stage HITL workflow)
    run_tests(test_file)           # Execute pytest suite
```

**MCP Integration**: Analysis Agent uses professional refactoring tools via MCP:
- **Rope**: Refactoring analysis
- **Radon**: Complexity metrics (cyclomatic, maintainability index)
- **Vulture**: Dead code detection
- **Pyrefly**: Type checking
- **McCabe**: Complexity analysis
- **Complexipy**: Advanced complexity metrics

### Session State & Memory

- **Session State**: Tracks files processed, proposals approved/rejected, metrics
- **Memory Bank**: Stores approval patterns and rejection reasons to learn human preferences
- **Checkpoints**: Records every HITL decision with timestamps and feedback

## ğŸš€ Getting Started

### Prerequisites

- Python 3.10+
- Gemini API key ([Get one here](https://aistudio.google.com/app/api-keys))

### Installation

```bash
# Clone this repository
cd "AI Agents Intensive"

# Install dependencies
pip install python-dotenv google-genai google-adk ipywidgets

# Set up API key
echo "GOOGLE_API_KEY=your_api_key_here" > code/.env
```

### Running the System

1. **Open the notebook**:
   ```bash
   jupyter notebook code/arc-dsl-refactoring-agent.ipynb
   ```

2. **Execute cells sequentially** (1-13):
   - Cells 1-4: Setup and configuration
   - Cells 5-8: Initialize tools, memory, and agents
   - Cell 9: HITL checkpoint interface
   - Cell 10: Workflow execution
   - Cells 11-12: Metrics and reporting
   - Cell 13: Run the system

3. **Interact with HITL checkpoints**:
   - Review formatted analysis, proposal, and validation
   - Choose: `approve`, `skip`, `reject`, or `abort`
   - Provide feedback for rejected proposals
   - System learns from your decisions and continues
   - Abort cleanly stops the workflow at any point

### Example Session

```
ğŸ“Š ANALYSIS SUMMARY
--------------------------------------------------------------------------------
  ğŸ” Issues Found: 8
     1. [HIGH] type_ambiguity at line 45
        Union[Grid, np.ndarray] creates type confusion...
     2. [MEDIUM] isinstance_check at line 127
        Multiple isinstance checks indicate need for type refinement...
  
  ğŸ“¦ Function Grouping Opportunities: 3
     1. 12 functions with signature: (Grid) -> Grid

  ğŸ’¡ Top Recommendations:
     1. [Priority 1, Risk: low] Replace Union types with dedicated classes...

================================================================================
ğŸ”¨ REFACTORING PROPOSAL
--------------------------------------------------------------------------------
  ğŸ¯ Target: Eliminate Union[Grid, np.ndarray] type ambiguity
  ğŸ“‹ Strategy: Create dedicated Grid class with np.ndarray wrapper...
  ğŸ“ Proposed Changes: 1 file(s)
     1. arc_types.py: ~45 lines
        Before: Grid = Union[List[List[int]], np.ndarray]...
        After:  class Grid: def __init__(self, data: np.ndarray)...

================================================================================
âœ… VALIDATION RESULTS
--------------------------------------------------------------------------------
  âœ… Overall Status: PASS
  âœ… Backward Compatible: True
  
  âš ï¸ Risks Identified: 2
     1. Existing code using isinstance(x, np.ndarray) needs wrapper...
     2. Performance impact minimal but requires testing...

================================================================================
DECISION OPTIONS:
  â€¢ approve (a/yes/y) - Apply this refactoring
  â€¢ skip (s)          - Skip this file, continue to next
  â€¢ reject (r/no/n)   - Reject this refactoring
  â€¢ abort (stop/quit) - Stop the entire workflow
================================================================================

ğŸ¤” Your decision: approve

âœ… Refactoring APPROVED
ğŸ“ Generating documentation...
âœ“ Documentation generated
```

## ğŸ“Š Key Concepts Demonstrated

This project demonstrates **7 out of 8** core course concepts:

- âœ… **Multi-agent system**: 5 specialized agents (Coordinator, Analysis, Refactor, Validation, Documentation) with sequential workflow
- âœ… **Tools - Custom**: 5 custom tools (read_file, write_file, analyze_type_usage, find_function_signatures, run_tests)
- âœ… **Tools - MCP**: mcp-python-refactoring integration (Rope, Radon, Vulture, Pyrefly, McCabe, Complexipy)
- âœ… **Sessions & Memory**: session_state dict tracking + memory_bank for learning human preferences
- âœ… **Observability**: RefactoringMetrics class + file/console logging with DEBUG/INFO levels
- âœ… **Context engineering**: Specialized system prompts per agent role
- âœ… **Agent evaluation**: Automated pytest testing + two-stage HITL validation + metrics
- âœ… **Gemini**: Gemini 2.5 Flash Lite powers all 5 agents
- â³ **Deployment**: Cloud Run (planned)

## ğŸ“ˆ Results & Metrics

### Refactoring Impact (Per Session)

| Metric | Target | Status |
|--------|--------|--------|
| isinstance checks removed | 150+ | Tracked |
| Union types eliminated | 4 | Tracked |
| Functions grouped | 20+ | Tracked |
| Test coverage maintained | 100% | Validated |
| Backward compatibility | Yes | Required |

### Kaggle Scoring Progress

**Current: 95/100 points**

- âœ… Pitch (30/30): Architecture docs, innovative approach
- âœ… Implementation (45/50): Core system + observability
- âœ… Documentation (20/20): Comprehensive README
- ğŸ”„ Bonus (5/20): Gemini integrated, deployment pending

**Target: 100/100 points**

## ğŸ”§ Technical Implementation

### Agent System (Gemini-Powered)

```python
# Each agent uses Gemini 2.0 Flash with specialized prompts
analysis_agent = RefactoringAgent(
    name="Analysis Agent",
    system_prompt="""You analyze Python files for refactoring opportunities.
    Focus on type ambiguity and function grouping..."""
)

# Coordinator orchestrates multi-agent workflow
result = coordinator.process_file("arc-dsl/arc_types.py")
# Returns: {analysis, proposal, validation, metrics}
```

### Two-Stage HITL Workflow

**Stage 1: Checkpoint #1 - Review Proposal**
```python
def hitl_checkpoint(result):
    """First checkpoint: Review agent proposal before testing"""
    
    # Display formatted sections (parses JSON, extracts key info)
    print("ğŸ“Š ANALYSIS SUMMARY")
    print(_format_analysis(result['analysis']))  # Issues, grouping, recommendations
    
    print("ğŸ”¨ REFACTORING PROPOSAL")
    print(_format_proposal(result['proposal']))   # Target, strategy, changes
    
    print("âœ… VALIDATION RESULTS")
    print(_format_validation(result['validation']))  # Status, risks, compatibility
    
    # Present clear decision options
    print("DECISION OPTIONS:")
    print("  â€¢ approve (a/yes/y) - Apply this refactoring and run tests")
    print("  â€¢ skip (s)          - Skip this file, continue to next")
    print("  â€¢ reject (r/no/n)   - Reject this refactoring")
    print("  â€¢ abort (stop/quit) - Stop the entire workflow")
    
    decision = input("Your decision: ").strip().lower()
    
    if decision in ['approve', 'a', 'yes', 'y']:
        store_memory('approval', context=result['file'])
        return {'status': 'approve'}  # Proceed to Stage 2
    # ... handle skip/reject/abort
```

**Stage 2: Apply, Test, and Checkpoint #2 - Commit/Rollback**
```python
# If approved at Checkpoint #1:

# 1. Apply refactoring and create backup
backup_path = write_file(file_path, refactored_code)  # Auto-creates timestamped backup

# 2. Run automated tests
test_result = subprocess.run(['python', '-m', 'pytest', 'arc-dsl/tests.py', ...])
test_passed = (test_result.returncode == 0)

# 3. Second checkpoint: Show test results
print("ğŸ‘¤ CHECKPOINT #2: COMMIT OR ROLLBACK")
print(f"ğŸ§ª Test Result: {'âœ… PASSED' if test_passed else 'âŒ FAILED'}")
print(f"ğŸ’¾ Backup: {backup_path}")

print("DECISION OPTIONS:")
if test_passed:
    print("  â€¢ commit (c/yes/y)  - Keep the changes (tests passed!)")
    print("  â€¢ rollback (r/no/n) - Restore backup (despite passing tests)")
else:
    print("  â€¢ commit (c/yes/y)  - Keep the changes (despite test failures)")
    print("  â€¢ rollback (r/no/n) - Restore backup (recommended - tests failed!)")
print("  â€¢ abort (stop/quit) - Stop the entire workflow")

commit_decision = input("Your decision: ").strip().lower()

if commit_decision in ['rollback', 'r', 'no', 'n']:
    subprocess.run(['cp', backup_path, file_path])  # Restore original
    print("âœ… Original file restored")
elif commit_decision in ['commit', 'c', 'yes', 'y']:
    print("âœ… Changes committed")
    # Generate documentation, update metrics, etc.
```

**Key Features:**
- **Two Decision Points**: Review before testing, commit after seeing results
- **Automated Testing**: pytest runs automatically between checkpoints
- **Safe Rollback**: Timestamped backups enable instant restore
- **Test Transparency**: See exact pass/fail before committing
- **Smart Formatting**: Parses JSON, shows prioritized info (top 3 issues/risks)
- **Abort Anywhere**: Clean exit at either checkpoint
- **Memory Learning**: Stores all decisions for pattern recognition

### Observability & Metrics

```python
# All agents wrapped with observability
class ObservableRefactoringAgent:
    def call(self, prompt, context):
        metrics.log_agent_call(self.name)
        metrics.log_llm_request(prompt_length=len(prompt))
        # ... execute agent ...
        metrics.log_llm_request(response_length=len(response))
        return response

# Comprehensive metrics tracking
metrics = RefactoringMetrics()
# Tracks: agent calls, tool calls, LLM tokens, 
#         HITL decisions, errors

# After session:
metrics.display_summary()
# Shows complete breakdown of agent performance
```

**Observability Features:**
- **Logging**: DEBUG-level logs to `refactoring_agent.log`
- **Metrics**: Real-time tracking of agents, tools, LLM calls, HITL approvals
- **Tracing**: Complete session workflow with timestamps
- **Error Tracking**: All errors logged with context for debugging

```python
# System learns from human decisions
memory_bank = {
    'approval_patterns': [
        {'context': 'arc_types.py', 'proposal_type': 'eliminate_union'},
    ],
    'rejection_reasons': [
        {'context': 'dsl.py', 'reason': 'Changes too large, split into smaller PRs'},
    ],
    'preferences': {
        'incremental_changes': True,
        'backward_compatibility': True
    }
}
```

## ğŸ“š Documentation

- **[Analysis Document](doc/analysis-arcDslRefactoringTargets.md)**: 600+ lines detailing refactoring targets
- **[Architecture Document](doc/architecture-arcDslRefactoringAgent.md)**: 1000+ lines with system design
- **[Progress Tracker](doc/progress-arcDslRefactoringAgent.md)**: Step-by-step implementation status
- **[Jupyter Notebook](code/arc-dsl-refactoring-agent.ipynb)**: Complete working implementation

## ğŸ¯ Why Freestyle Track?

This project exemplifies the Freestyle track's spirit:

1. **Innovative**: Meta-agents (agents that improve code) are unconventional
2. **Unclassifiable**: Doesn't fit neatly into other tracks (not purely chat, productivity, or game)
3. **Meaningful Agent Use**: Agents are centralâ€”impossible to solve without multi-agent collaboration
4. **Real-World Value**: Addresses actual software engineering pain point

## ğŸš€ Next Steps

- [x] **Step 1-3**: Analysis, architecture, implementation âœ…
- [x] **Step 4**: Observability (LoggingPlugin + Metrics) âœ…
- [ ] **Step 5**: Deploy to Cloud Run (+5 pts deployment)
- [ ] **Step 6**: Create NotebookLM video (+10 pts)
- [ ] **Submit**: Kaggle writeup before Dec 1, 2025

## ğŸ“„ License

Apache 2.0 (matching Kaggle course materials)

## ğŸ™ Acknowledgments

- **ARC-DSL**: Michael Hodel's excellent DSL for ARC challenges
- **Google ADK**: Agent Development Kit team
- **Kaggle**: Agents Intensive course instructors

---

**Built for**: Kaggle Agents Intensive Capstone Project  
**Track**: Freestyle  
**Date**: November 2025  
**Target Score**: 100/100 points
